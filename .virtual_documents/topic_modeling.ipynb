


import pandas as pd
import gensim
from gensim.corpora.dictionary import Dictionary
from sklearn.feature_extraction.text import CountVectorizer
from nltk.corpus import stopwords
import nltk
nltk.download('stopwords')

# inputs
num_topics = 5

# Load your data
df = pd.read_csv('data-files/transcript_data_combined.csv')

# Preprocessing: Tokenize and clean the text data
stop_words = set(stopwords.words('english'))

def preprocess(text):
    return [word for word in text.lower().split() if word not in stop_words]

# Apply preprocessing to the 'documents' column
processed_docs = df['Transcript'].dropna().apply(preprocess)

# Create a Gensim dictionary and corpus
dictionary = Dictionary(processed_docs)
corpus = [dictionary.doc2bow(doc) for doc in processed_docs]

# Train LDA model using Gensim
lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)

# Create a DataFrame to store the topics and their words
topics_list = []

# Print the topics
for idx, topic in lda_model.print_topics(-1):
    print(f"Topic {idx}: {topic}")
    
for idx, topic in lda_model.print_topics(-1):
    # Clean and split the topic string into words
    topic_words = topic.replace('"', '').split(' + ')
    topic_words = [word.split('*')[1].strip() for word in topic_words]
    topics_list.append({'Topic': idx, 'Words': ', '.join(topic_words)})

# Convert the list to a DataFrame
topics_df = pd.DataFrame(topics_list)

# Display the DataFrame nicely
print(topics_df)



# predict document topics
[lda_model.get_document_topics(bow) for bow in corpus]
# need to get the index and put this into the original df


# consider additional stop words based on word cloud
# Import the wordcloud library
from wordcloud import WordCloud

# Join the different processed titles together.
long_string = ' '.join(processed_docs.map(lambda x: ' '.join(x)))

# Create a WordCloud object
wordcloud = WordCloud(background_color="white", max_words=1000, contour_width=3, contour_color='steelblue')

# Generate a word cloud
wordcloud.generate(long_string)

# Visualize the word cloud
wordcloud.to_image()


# visualization of LDA

