{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m5cSe7JEIHi",
        "outputId": "40ac9729-8e03-401b-cb8c-8ae3f0ee40a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                         neg       neu  \\\n",
            "YouTube URL                                                              \n",
            "https://www.youtube.com/live/XokApnr_Cak?si=7eV...  0.040576  0.786054   \n",
            "https://youtu.be/Q5TIZnhXX7Q?si=agpeKU04EQ-AtdJ_    0.066934  0.756083   \n",
            "https://youtu.be/-ofJu78Wpn0?si=H_BZ0KSYr_raPUac    0.069800  0.740400   \n",
            "https://youtu.be/qc5NgBZXdtI?si=imCepjoyPvY2Jmcq    0.086038  0.759319   \n",
            "\n",
            "                                                         pos  compound  \n",
            "YouTube URL                                                             \n",
            "https://www.youtube.com/live/XokApnr_Cak?si=7eV...  0.173315  0.543090  \n",
            "https://youtu.be/Q5TIZnhXX7Q?si=agpeKU04EQ-AtdJ_    0.176945  0.452686  \n",
            "https://youtu.be/-ofJu78Wpn0?si=H_BZ0KSYr_raPUac    0.189825  0.370946  \n",
            "https://youtu.be/qc5NgBZXdtI?si=imCepjoyPvY2Jmcq    0.154643  0.261072  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Load CSV file\n",
        "csvFile = pd.read_csv('transcript_data_combined.csv')\n",
        "\n",
        "# Download VADER lexicon\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Set up the analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define expanded custom lexicon for political-related sentiments\n",
        "def get_political_sentiment(sentence):\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "    # Expanded custom lexicon for political sentiments\n",
        "    politicalWords = {\n",
        "        # Positive Sentiment Words\n",
        "        'progress': 2.0, 'peaceful': 2.5, 'visionary': 2.3, 'hopeful': 2.2,\n",
        "        'inclusive': 2.0, 'unity': 1.8, 'reform': 1.7, 'growth': 1.9,\n",
        "        'prosperity': 2.0, 'strong': 2.4, 'freedom': 1.8, 'justice': 1.9,\n",
        "        'opportunity': 2.5, 'equality': 2.5, 'empower': 2.4, 'resolve': 2.3,\n",
        "        'bright': 2.2, 'leadership': 2.1, 'diplomacy': 2.0, 'accountability': 2.1,\n",
        "        'collaboration': 2.0, 'integrity': 2.3, 'innovation': 2.0, 'resilience': 1.9,\n",
        "        'solidarity': 2.2, 'compassion': 2.4, 'inclusive': 2.3, 'patriotism': 2.1,\n",
        "        'courage': 2.5, 'dedication': 2.4, 'responsibility': 2.3, 'sacrifice': 2.2,\n",
        "\n",
        "        # Negative Sentiment Words\n",
        "        'divisive': -2.5, 'corruption': -2.0, 'crisis': -2.2, 'chaos': -2.3,\n",
        "        'conflict': -2.5, 'threat': -2.0, 'oppression': -1.8, 'failure': -2.5,\n",
        "        'unrest': -2.1, 'inequality': -2.3, 'exploitation': -2.0, 'injustice': -2.4,\n",
        "        'scandal': -2.5, 'lies': -2.4, 'betrayal': -2.3, 'turmoil': -2.1,\n",
        "        'fear': -2.3, 'authoritarian': -2.4, 'censorship': -2.2, 'division': -2.0,\n",
        "        'repression': -2.3, 'mismanagement': -2.1, 'controversy': -1.9, 'bias': -2.2,\n",
        "        'hypocrisy': -2.4, 'slander': -2.1, 'greed': -2.5, 'violence': -2.4,\n",
        "        'deception': -2.5, 'propaganda': -2.3, 'polarization': -2.2, 'abuse': -2.5,\n",
        "\n",
        "        # Neutral/Context-Dependent Words\n",
        "        'leader': 1.0, 'policy': 1.2, 'campaign': 1.5, 'candidate': 0.5,\n",
        "        'debate': 0.7, 'vote': 1.5, 'agenda': 1.0, 'law': 1.2,\n",
        "        'economy': 0.9, 'strategy': 1.1, 'movement': 1.0, 'security': 1.0,\n",
        "        'constitution': 0.8, 'foreign': -1.0, 'budget': 1.0, 'tax': -1.0,\n",
        "        'legislation': 0.8, 'government': 1.0, 'executive': 0.7, 'judiciary': 0.7,\n",
        "        'diplomat': 1.0, 'coalition': 1.1, 'treaty': 1.2, 'electoral': 1.0,\n",
        "        'sanction': -1.5, 'lobbyist': -0.8, 'legislature': 1.0, 'bureaucracy': -1.2\n",
        "    }\n",
        "    sid.lexicon.update(politicalWords)  # Update the lexicon\n",
        "    score = sid.polarity_scores(sentence)  # Get sentiment scores\n",
        "    return score  # Return full sentiment scores\n",
        "\n",
        "# Convert any non-string entries in the 'Transcript' column to empty strings\n",
        "csvFile['Transcript'] = csvFile['Transcript'].astype(str)\n",
        "\n",
        "# Create empty lists to store sentiment scores\n",
        "neg = []\n",
        "neu = []\n",
        "pos = []\n",
        "compound = []\n",
        "\n",
        "# Loop through the texts and get the sentiment scores using the updated function\n",
        "for text in csvFile[\"Transcript\"]:\n",
        "    scores = get_political_sentiment(text)\n",
        "    neg.append(scores['neg'])\n",
        "    neu.append(scores['neu'])\n",
        "    pos.append(scores['pos'])\n",
        "    compound.append(scores['compound'])\n",
        "\n",
        "# Add sentiment scores as new columns to the DataFrame\n",
        "csvFile['neg'] = neg\n",
        "csvFile['neu'] = neu\n",
        "csvFile['pos'] = pos\n",
        "csvFile['compound'] = compound\n",
        "\n",
        "# Group by 'YouTube URL' and calculate the average sentiment score per group\n",
        "sentiment_avg = csvFile.groupby(\"YouTube URL\")[[\"neg\", \"neu\", \"pos\", \"compound\"]].mean().sort_values(by=\"compound\", ascending=False)\n",
        "print(sentiment_avg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Load CSV file\n",
        "csvFile = pd.read_csv('transcript_data_combined.csv')\n",
        "\n",
        "# Download VADER lexicon\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Set up the analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define expanded custom lexicon for political-related sentiments\n",
        "def get_political_sentiment(sentence):\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "    # Expanded custom lexicon for political sentiments\n",
        "    politicalWords = {\n",
        "        # Positive Sentiment Words\n",
        "        'progress': 2.0, 'peaceful': 2.5, 'visionary': 2.3, 'hopeful': 2.2,\n",
        "        'inclusive': 2.0, 'unity': 1.8, 'reform': 1.7, 'growth': 1.9,\n",
        "        'prosperity': 2.0, 'strong': 2.4, 'freedom': 1.8, 'justice': 1.9,\n",
        "        'opportunity': 2.5, 'equality': 2.5, 'empower': 2.4, 'resolve': 2.3,\n",
        "        'bright': 2.2, 'leadership': 2.1, 'diplomacy': 2.0, 'accountability': 2.1,\n",
        "        'collaboration': 2.0, 'integrity': 2.3, 'innovation': 2.0, 'resilience': 1.9,\n",
        "        'solidarity': 2.2, 'compassion': 2.4, 'inclusive': 2.3, 'patriotism': 2.1,\n",
        "        'courage': 2.5, 'dedication': 2.4, 'responsibility': 2.3, 'sacrifice': 2.2,\n",
        "\n",
        "        # Negative Sentiment Words\n",
        "        'divisive': -2.5, 'corruption': -2.0, 'crisis': -2.2, 'chaos': -2.3,\n",
        "        'conflict': -2.5, 'threat': -2.0, 'oppression': -1.8, 'failure': -2.5,\n",
        "        'unrest': -2.1, 'inequality': -2.3, 'exploitation': -2.0, 'injustice': -2.4,\n",
        "        'scandal': -2.5, 'lies': -2.4, 'betrayal': -2.3, 'turmoil': -2.1,\n",
        "        'fear': -2.3, 'authoritarian': -2.4, 'censorship': -2.2, 'division': -2.0,\n",
        "        'repression': -2.3, 'mismanagement': -2.1, 'controversy': -1.9, 'bias': -2.2,\n",
        "        'hypocrisy': -2.4, 'slander': -2.1, 'greed': -2.5, 'violence': -2.4,\n",
        "        'deception': -2.5, 'propaganda': -2.3, 'polarization': -2.2, 'abuse': -2.5,\n",
        "\n",
        "        # Neutral/Context-Dependent Words\n",
        "        'leader': 1.0, 'policy': 1.2, 'campaign': 1.5, 'candidate': 0.5,\n",
        "        'debate': 0.7, 'vote': 1.5, 'agenda': 1.0, 'law': 1.2,\n",
        "        'economy': 0.9, 'strategy': 1.1, 'movement': 1.0, 'security': 1.0,\n",
        "        'constitution': 0.8, 'foreign': -1.0, 'budget': 1.0, 'tax': -1.0,\n",
        "        'legislation': 0.8, 'government': 1.0, 'executive': 0.7, 'judiciary': 0.7,\n",
        "        'diplomat': 1.0, 'coalition': 1.1, 'treaty': 1.2, 'electoral': 1.0,\n",
        "        'sanction': -1.5, 'lobbyist': -0.8, 'legislature': 1.0, 'bureaucracy': -1.2\n",
        "    }\n",
        "    sid.lexicon.update(politicalWords)  # Update the lexicon\n",
        "    score = sid.polarity_scores(sentence)  # Get sentiment scores\n",
        "    return score  # Return full sentiment scores\n",
        "\n",
        "# Convert any non-string entries in the 'Transcript' column to empty strings\n",
        "csvFile['Transcript'] = csvFile['Transcript'].astype(str)\n",
        "\n",
        "# Create empty lists to store sentiment scores\n",
        "neg = []\n",
        "neu = []\n",
        "pos = []\n",
        "compound = []\n",
        "\n",
        "# Loop through the texts and get the sentiment scores using the updated function\n",
        "for text in csvFile[\"Transcript\"]:\n",
        "    scores = get_political_sentiment(text)\n",
        "    neg.append(scores['neg'])\n",
        "    neu.append(scores['neu'])\n",
        "    pos.append(scores['pos'])\n",
        "    compound.append(scores['compound'])\n",
        "\n",
        "# Add sentiment scores as new columns to the DataFrame\n",
        "csvFile['neg'] = neg\n",
        "csvFile['neu'] = neu\n",
        "csvFile['pos'] = pos\n",
        "csvFile['compound'] = compound\n",
        "\n",
        "# Group by 'YouTube URL' and calculate the average sentiment score per group\n",
        "sentiment_avg = csvFile.groupby(\"YouTube URL\")[[\"neg\", \"neu\", \"pos\", \"compound\"]].mean().sort_values(by=\"compound\", ascending=False)\n",
        "\n",
        "# Save the result as a CSV file\n",
        "sentiment_avg.to_csv('grouped_sentiment_analysis.csv', index=True)\n",
        "print(\"Sentiment analysis results saved to 'grouped_sentiment_analysis.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTF6YdC7FiQ_",
        "outputId": "ace1092b-a2ff-46d2-806f-3e0d2444a1db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment analysis results saved to 'grouped_sentiment_analysis.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Load CSV file\n",
        "csvFile = pd.read_csv('transcript_data_combined.csv')\n",
        "\n",
        "# Download VADER lexicon\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Set up the analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define expanded custom lexicon for political-related sentiments\n",
        "def get_political_sentiment(sentence):\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "    # Expanded custom lexicon for political sentiments\n",
        "    politicalWords = {\n",
        "        # Positive Sentiment Words\n",
        "        'progress': 2.0, 'peaceful': 2.5, 'visionary': 2.3, 'hopeful': 2.2,\n",
        "        'inclusive': 2.0, 'unity': 1.8, 'reform': 1.7, 'growth': 1.9,\n",
        "        'prosperity': 2.0, 'strong': 2.4, 'freedom': 1.8, 'justice': 1.9,\n",
        "        'opportunity': 2.5, 'equality': 2.5, 'empower': 2.4, 'resolve': 2.3,\n",
        "        'bright': 2.2, 'leadership': 2.1, 'diplomacy': 2.0, 'accountability': 2.1,\n",
        "        'collaboration': 2.0, 'integrity': 2.3, 'innovation': 2.0, 'resilience': 1.9,\n",
        "        'solidarity': 2.2, 'compassion': 2.4, 'inclusive': 2.3, 'patriotism': 2.1,\n",
        "        'courage': 2.5, 'dedication': 2.4, 'responsibility': 2.3, 'sacrifice': 2.2,\n",
        "\n",
        "        # Negative Sentiment Words\n",
        "        'divisive': -2.5, 'corruption': -2.0, 'crisis': -2.2, 'chaos': -2.3,\n",
        "        'conflict': -2.5, 'threat': -2.0, 'oppression': -1.8, 'failure': -2.5,\n",
        "        'unrest': -2.1, 'inequality': -2.3, 'exploitation': -2.0, 'injustice': -2.4,\n",
        "        'scandal': -2.5, 'lies': -2.4, 'betrayal': -2.3, 'turmoil': -2.1,\n",
        "        'fear': -2.3, 'authoritarian': -2.4, 'censorship': -2.2, 'division': -2.0,\n",
        "        'repression': -2.3, 'mismanagement': -2.1, 'controversy': -1.9, 'bias': -2.2,\n",
        "        'hypocrisy': -2.4, 'slander': -2.1, 'greed': -2.5, 'violence': -2.4,\n",
        "        'deception': -2.5, 'propaganda': -2.3, 'polarization': -2.2, 'abuse': -2.5,\n",
        "\n",
        "        # Neutral/Context-Dependent Words\n",
        "        'leader': 1.0, 'policy': 1.2, 'campaign': 1.5, 'candidate': 0.5,\n",
        "        'debate': 0.7, 'vote': 1.5, 'agenda': 1.0, 'law': 1.2,\n",
        "        'economy': 0.9, 'strategy': 1.1, 'movement': 1.0, 'security': 1.0,\n",
        "        'constitution': 0.8, 'foreign': -1.0, 'budget': 1.0, 'tax': -1.0,\n",
        "        'legislation': 0.8, 'government': 1.0, 'executive': 0.7, 'judiciary': 0.7,\n",
        "        'diplomat': 1.0, 'coalition': 1.1, 'treaty': 1.2, 'electoral': 1.0,\n",
        "        'sanction': -1.5, 'lobbyist': -0.8, 'legislature': 1.0, 'bureaucracy': -1.2\n",
        "    }\n",
        "    sid.lexicon.update(politicalWords)  # Update the lexicon\n",
        "    score = sid.polarity_scores(sentence)  # Get sentiment scores\n",
        "    return score  # Return full sentiment scores\n",
        "\n",
        "# Convert any non-string entries in the 'Transcript' column to empty strings\n",
        "csvFile['Transcript'] = csvFile['Transcript'].astype(str)\n",
        "\n",
        "# Create empty lists to store sentiment scores\n",
        "neg = []\n",
        "neu = []\n",
        "pos = []\n",
        "compound = []\n",
        "\n",
        "# Loop through the texts and get the sentiment scores using the updated function\n",
        "for text in csvFile[\"Transcript\"]:\n",
        "    scores = get_political_sentiment(text)\n",
        "    neg.append(scores['neg'])\n",
        "    neu.append(scores['neu'])\n",
        "    pos.append(scores['pos'])\n",
        "    compound.append(scores['compound'])\n",
        "\n",
        "# Add sentiment scores as new columns to the DataFrame\n",
        "csvFile['neg'] = neg\n",
        "csvFile['neu'] = neu\n",
        "csvFile['pos'] = pos\n",
        "csvFile['compound'] = compound\n",
        "\n",
        "# Save the result as a CSV file with sentiment scores for each row\n",
        "csvFile.to_csv('individual_sentiment_analysis.csv', index=False)\n",
        "print(\"Individual sentiment analysis results saved to 'individual_sentiment_analysis.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5ATVuwPM3JQ",
        "outputId": "55dc5f6b-cd4d-4016-edcf-c13e7ecca63f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Individual sentiment analysis results saved to 'individual_sentiment_analysis.csv'\n"
          ]
        }
      ]
    }
  ]
}